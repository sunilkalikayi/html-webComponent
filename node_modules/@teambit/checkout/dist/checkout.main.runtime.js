"use strict";

var _interopRequireDefault = require("@babel/runtime/helpers/interopRequireDefault");
require("core-js/modules/es.array.iterator.js");
require("core-js/modules/es.promise.js");
Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = exports.CheckoutMain = void 0;
function _defineProperty2() {
  const data = _interopRequireDefault(require("@babel/runtime/helpers/defineProperty"));
  _defineProperty2 = function () {
    return data;
  };
  return data;
}
function _cli() {
  const data = require("@teambit/cli");
  _cli = function () {
    return data;
  };
  return data;
}
function _logger() {
  const data = require("@teambit/logger");
  _logger = function () {
    return data;
  };
  return data;
}
function _workspace() {
  const data = _interopRequireDefault(require("@teambit/workspace"));
  _workspace = function () {
    return data;
  };
  return data;
}
function _legacyBitId() {
  const data = require("@teambit/legacy-bit-id");
  _legacyBitId = function () {
    return data;
  };
  return data;
}
function _bitError() {
  const data = require("@teambit/bit-error");
  _bitError = function () {
    return data;
  };
  return data;
}
function _loaderMessages() {
  const data = require("@teambit/legacy/dist/cli/loader/loader-messages");
  _loaderMessages = function () {
    return data;
  };
  return data;
}
function _constants() {
  const data = require("@teambit/legacy/dist/constants");
  _constants = function () {
    return data;
  };
  return data;
}
function _checkoutVersion() {
  const data = require("@teambit/legacy/dist/consumer/versions-ops/checkout-version");
  _checkoutVersion = function () {
    return data;
  };
  return data;
}
function _mergeVersion() {
  const data = require("@teambit/legacy/dist/consumer/versions-ops/merge-version");
  _mergeVersion = function () {
    return data;
  };
  return data;
}
function _generalError() {
  const data = _interopRequireDefault(require("@teambit/legacy/dist/error/general-error"));
  _generalError = function () {
    return data;
  };
  return data;
}
function _exceptions() {
  const data = require("@teambit/legacy/dist/consumer/exceptions");
  _exceptions = function () {
    return data;
  };
  return data;
}
function _pMapSeries() {
  const data = _interopRequireDefault(require("p-map-series"));
  _pMapSeries = function () {
    return data;
  };
  return data;
}
function _bitId() {
  const data = require("@teambit/legacy/dist/bit-id");
  _bitId = function () {
    return data;
  };
  return data;
}
function _repositories() {
  const data = require("@teambit/legacy/dist/scope/repositories");
  _repositories = function () {
    return data;
  };
  return data;
}
function _manyComponentsWriter() {
  const data = _interopRequireDefault(require("@teambit/legacy/dist/consumer/component-ops/many-components-writer"));
  _manyComponentsWriter = function () {
    return data;
  };
  return data;
}
function _scopeComponentsImporter() {
  const data = _interopRequireDefault(require("@teambit/legacy/dist/scope/component-ops/scope-components-importer"));
  _scopeComponentsImporter = function () {
    return data;
  };
  return data;
}
function _checkoutCmd() {
  const data = require("./checkout-cmd");
  _checkoutCmd = function () {
    return data;
  };
  return data;
}
function _checkout() {
  const data = require("./checkout.aspect");
  _checkout = function () {
    return data;
  };
  return data;
}
function ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); enumerableOnly && (symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; })), keys.push.apply(keys, symbols); } return keys; }
function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = null != arguments[i] ? arguments[i] : {}; i % 2 ? ownKeys(Object(source), !0).forEach(function (key) { (0, _defineProperty2().default)(target, key, source[key]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } return target; }
class CheckoutMain {
  constructor(workspace, logger) {
    this.workspace = workspace;
    this.logger = logger;
  }
  async checkout(checkoutProps) {
    var _checkoutProps$ids;
    const consumer = this.workspace.consumer;
    const {
      version,
      ids,
      promptMergeOptions
    } = checkoutProps;
    await this.syncNewComponents(checkoutProps);
    const bitIds = _bitId().BitIds.fromArray((ids === null || ids === void 0 ? void 0 : ids.map(id => id._legacy)) || []);
    await consumer.scope.import(bitIds, false);
    const {
      components
    } = await consumer.loadComponents(bitIds);
    const getAllComponentsStatus = async () => {
      const tmp = new (_repositories().Tmp)(consumer.scope);
      try {
        const componentsStatusP = components.map(component => this.getComponentStatus(component, checkoutProps));
        const componentsStatus = await Promise.all(componentsStatusP);
        await tmp.clear();
        return componentsStatus;
      } catch (err) {
        await tmp.clear();
        throw err;
      }
    };
    const allComponentsStatus = await getAllComponentsStatus();
    const componentWithConflict = allComponentsStatus.find(component => component.mergeResults && component.mergeResults.hasConflicts);
    if (componentWithConflict) {
      if (!promptMergeOptions && !checkoutProps.mergeStrategy) {
        throw new (_generalError().default)(`automatic merge has failed for component ${componentWithConflict.id.toStringWithoutVersion()}.\nplease use "--manual" to manually merge changes or use "--theirs / --ours" to choose one of the conflicted versions`);
      }
      if (!checkoutProps.mergeStrategy) checkoutProps.mergeStrategy = await (0, _mergeVersion().getMergeStrategyInteractive)();
    }
    const failedComponents = allComponentsStatus.filter(componentStatus => componentStatus.failureMessage).map(componentStatus => ({
      id: componentStatus.id,
      failureMessage: componentStatus.failureMessage,
      unchangedLegitimately: componentStatus.unchangedLegitimately
    }));
    const succeededComponents = allComponentsStatus.filter(componentStatus => !componentStatus.failureMessage);
    // do not use Promise.all for applyVersion. otherwise, it'll write all components in parallel,
    // which can be an issue when some components are also dependencies of others
    const checkoutPropsLegacy = _objectSpread(_objectSpread({}, checkoutProps), {}, {
      ids: (_checkoutProps$ids = checkoutProps.ids) === null || _checkoutProps$ids === void 0 ? void 0 : _checkoutProps$ids.map(id => id._legacy)
    });
    const componentsResults = await (0, _pMapSeries().default)(succeededComponents, ({
      id,
      componentFromFS,
      mergeResults
    }) => {
      return (0, _checkoutVersion().applyVersion)(consumer, id, componentFromFS, mergeResults, checkoutPropsLegacy);
    });
    (0, _checkoutVersion().markFilesToBeRemovedIfNeeded)(succeededComponents, componentsResults);
    const componentsWithDependencies = componentsResults.map(c => c.component).filter(c => c);
    const leftUnresolvedConflicts = componentWithConflict && checkoutProps.mergeStrategy === 'manual';
    if (componentsWithDependencies.length) {
      const manyComponentsWriter = new (_manyComponentsWriter().default)({
        consumer,
        componentsWithDependencies,
        installNpmPackages: !checkoutProps.skipNpmInstall && !leftUnresolvedConflicts,
        override: true,
        verbose: checkoutProps.verbose,
        resetConfig: checkoutProps.reset
      });
      await manyComponentsWriter.writeAll();
      await (0, _checkoutVersion().deleteFilesIfNeeded)(componentsResults, consumer);
    }
    const appliedVersionComponents = componentsResults.map(c => c.applyVersionResult);
    return {
      components: appliedVersionComponents,
      version,
      failedComponents,
      leftUnresolvedConflicts
    };
  }
  async checkoutByCLIValues(to, componentPattern, checkoutProps) {
    this.logger.setStatusLine(_loaderMessages().BEFORE_CHECKOUT);
    if (!this.workspace) throw new (_exceptions().ConsumerNotFound)();
    const consumer = this.workspace.consumer;
    await this.parseValues(to, componentPattern, checkoutProps);
    const checkoutResults = await this.checkout(checkoutProps);
    await consumer.onDestroy();
    return checkoutResults;
  }
  async syncNewComponents({
    ids,
    head
  }) {
    if (!head) return;
    const notExported = ids === null || ids === void 0 ? void 0 : ids.filter(id => !id._legacy.hasScope()).map(id => id._legacy.changeScope(id.scope));
    const scopeComponentsImporter = new (_scopeComponentsImporter().default)(this.workspace.consumer.scope);
    try {
      await scopeComponentsImporter.importManyDeltaWithoutDeps(_bitId().BitIds.fromArray(notExported || []), true);
    } catch (err) {
      // don't stop the process. it's possible that the scope doesn't exist yet because these are new components
      this.logger.error(`unable to sync new components due to an error`, err);
    }
  }
  async parseValues(to, componentPattern, checkoutProps) {
    if (to === _constants().HEAD) checkoutProps.head = true;else if (to === _constants().LATEST) throw new (_bitError().BitError)(`"latest" was deprecated a while ago, please use "head" instead`);else if (to === 'reset') checkoutProps.reset = true;else {
      if (!_legacyBitId().BitId.isValidVersion(to)) throw new (_bitError().BitError)(`the specified version "${to}" is not a valid version`);
      checkoutProps.version = to;
    }
    if (checkoutProps.head && !componentPattern) {
      if (checkoutProps.all) {
        this.logger.console(`"--all" is deprecated for "bit checkout ${_constants().HEAD}", please omit it.`);
      }
      checkoutProps.all = true;
    }
    if (componentPattern && checkoutProps.all) {
      throw new (_generalError().default)('please specify either [component-pattern] or --all, not both');
    }
    if (!componentPattern && !checkoutProps.all) {
      throw new (_generalError().default)('please specify [component-pattern] or use --all flag');
    }
    const ids = componentPattern ? await this.workspace.idsByPattern(componentPattern) : await this.workspace.listIds();
    checkoutProps.ids = ids.map(id => checkoutProps.head ? id.changeVersion(_constants().LATEST) : id);
  }
  async getComponentStatus(component, checkoutProps) {
    const consumer = this.workspace.consumer;
    const {
      version,
      head: latestVersion,
      reset
    } = checkoutProps;
    const repo = consumer.scope.objects;
    const componentModel = await consumer.scope.getModelComponentIfExist(component.id);
    const componentStatus = {
      id: component.id
    };
    const returnFailure = (msg, unchangedLegitimately = false) => {
      componentStatus.failureMessage = msg;
      componentStatus.unchangedLegitimately = unchangedLegitimately;
      return componentStatus;
    };
    if (!componentModel) {
      return returnFailure(`component ${component.id.toString()} is new, no version to checkout`, true);
    }
    const unmerged = repo.unmergedComponents.getEntry(component.name);
    if (!reset && unmerged) {
      return returnFailure(`component ${component.id.toStringWithoutVersion()} is in during-merge state, please snap/tag it first (or use bit merge --resolve/--abort)`);
    }
    const getNewVersion = async () => {
      // @ts-ignore AUTO-ADDED-AFTER-MIGRATION-PLEASE-FIX!
      if (reset) return component.id.version;
      // @ts-ignore if !reset the version is defined
      return latestVersion ? componentModel.latestIncludeRemote(repo) : version;
    };
    const newVersion = await getNewVersion();
    if (version && !latestVersion) {
      const hasVersion = await componentModel.hasVersion(version, repo);
      if (!hasVersion) return returnFailure(`component ${component.id.toStringWithoutVersion()} doesn't have version ${version}`);
    }
    const existingBitMapId = consumer.bitMap.getBitId(component.id, {
      ignoreVersion: true
    });
    const currentlyUsedVersion = existingBitMapId.version;
    if (!currentlyUsedVersion) {
      return returnFailure(`component ${component.id.toStringWithoutVersion()} is new`);
    }
    if (version && currentlyUsedVersion === version) {
      // it won't be relevant for 'reset' as it doesn't have a version
      return returnFailure(`component ${component.id.toStringWithoutVersion()} is already at version ${version}`);
    }
    if (latestVersion && currentlyUsedVersion === newVersion) {
      return returnFailure(`component ${component.id.toStringWithoutVersion()} is already at the latest version, which is ${newVersion}`, true);
    }
    const currentVersionObject = await componentModel.loadVersion(currentlyUsedVersion, repo);
    const isModified = await consumer.isComponentModified(currentVersionObject, component);
    if (!isModified && reset) {
      return returnFailure(`component ${component.id.toStringWithoutVersion()} is not modified`);
    }
    // this is tricky. imagine the user is 0.0.2+modification and wants to checkout to 0.0.1.
    // the base is 0.0.1, as it's the common version for 0.0.1 and 0.0.2. however, if we let git merge-file use the 0.0.1
    // as the base, then, it'll get the changes done since 0.0.1 to 0.0.1, which is nothing, and put them on top of
    // 0.0.2+modification. in other words, it won't make any change.
    // this scenario of checking out while there are modified files, is forbidden in Git. here, we want to simulate a similar
    // experience of "git stash", then "git checkout", then "git stash pop". practically, we want the changes done on 0.0.2
    // to be added to 0.0.1
    // if there is no modification, it doesn't go the threeWayMerge anyway, so it doesn't matter what the base is.
    const baseVersion = currentlyUsedVersion;
    const baseComponent = await componentModel.loadVersion(baseVersion, repo);
    let mergeResults;
    // if the component is not modified, no need to try merge the files, they will be written later on according to the
    // checked out version. same thing when no version is specified, it'll be reset to the model-version later.
    if (!reset && isModified) {
      const otherComponent = await componentModel.loadVersion(newVersion, repo);
      mergeResults = await (0, _mergeVersion().threeWayMerge)({
        consumer,
        otherComponent,
        otherLabel: newVersion,
        currentComponent: component,
        currentLabel: `${currentlyUsedVersion} modified`,
        baseComponent
      });
    }
    const versionRef = componentModel.getRef(newVersion);
    // @ts-ignore
    const componentVersion = await consumer.scope.getObject(versionRef.hash);
    const newId = component.id.changeVersion(newVersion);
    // @ts-ignore AUTO-ADDED-AFTER-MIGRATION-PLEASE-FIX!
    return {
      componentFromFS: component,
      componentFromModel: componentVersion,
      id: newId,
      mergeResults
    };
  }
  static async provider([cli, workspace, loggerMain]) {
    const logger = loggerMain.createLogger(_checkout().CheckoutAspect.id);
    const checkoutMain = new CheckoutMain(workspace, logger);
    cli.register(new (_checkoutCmd().CheckoutCmd)(checkoutMain));
    return checkoutMain;
  }
}
exports.CheckoutMain = CheckoutMain;
(0, _defineProperty2().default)(CheckoutMain, "slots", []);
(0, _defineProperty2().default)(CheckoutMain, "dependencies", [_cli().CLIAspect, _workspace().default, _logger().LoggerAspect]);
(0, _defineProperty2().default)(CheckoutMain, "runtime", _cli().MainRuntime);
_checkout().CheckoutAspect.addRuntime(CheckoutMain);
var _default = CheckoutMain;
exports.default = _default;

//# sourceMappingURL=checkout.main.runtime.js.map