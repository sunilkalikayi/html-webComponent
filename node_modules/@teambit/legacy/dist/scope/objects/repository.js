"use strict";

var _interopRequireDefault = require("@babel/runtime/helpers/interopRequireDefault");
require("core-js/modules/es.array.iterator.js");
require("core-js/modules/es.promise.js");
require("core-js/modules/es.regexp.exec.js");
require("core-js/modules/es.string.replace.js");
Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = void 0;
function _defineProperty2() {
  const data = _interopRequireDefault(require("@babel/runtime/helpers/defineProperty"));
  _defineProperty2 = function () {
    return data;
  };
  return data;
}
function _fsExtra() {
  const data = _interopRequireDefault(require("fs-extra"));
  _fsExtra = function () {
    return data;
  };
  return data;
}
function _asyncMutex() {
  const data = require("async-mutex");
  _asyncMutex = function () {
    return data;
  };
  return data;
}
function _lodash() {
  const data = require("lodash");
  _lodash = function () {
    return data;
  };
  return data;
}
function _componentVersion() {
  const data = require("@teambit/component-version");
  _componentVersion = function () {
    return data;
  };
  return data;
}
function path() {
  const data = _interopRequireWildcard(require("path"));
  path = function () {
    return data;
  };
  return data;
}
function _pMap() {
  const data = _interopRequireDefault(require("p-map"));
  _pMap = function () {
    return data;
  };
  return data;
}
function _constants() {
  const data = require("../../constants");
  _constants = function () {
    return data;
  };
  return data;
}
function _logger() {
  const data = _interopRequireDefault(require("../../logger/logger"));
  _logger = function () {
    return data;
  };
  return data;
}
function _utils() {
  const data = require("../../utils");
  _utils = function () {
    return data;
  };
  return data;
}
function _fsRemoveFile() {
  const data = _interopRequireDefault(require("../../utils/fs-remove-file"));
  _fsRemoveFile = function () {
    return data;
  };
  return data;
}
function _exceptions() {
  const data = require("../exceptions");
  _exceptions = function () {
    return data;
  };
  return data;
}
function _remoteLanes() {
  const data = _interopRequireDefault(require("../lanes/remote-lanes"));
  _remoteLanes = function () {
    return data;
  };
  return data;
}
function _unmergedComponents() {
  const data = _interopRequireDefault(require("../lanes/unmerged-components"));
  _unmergedComponents = function () {
    return data;
  };
  return data;
}
function _scopeMeta() {
  const data = _interopRequireDefault(require("../models/scopeMeta"));
  _scopeMeta = function () {
    return data;
  };
  return data;
}
function _componentsIndex() {
  const data = _interopRequireDefault(require("./components-index"));
  _componentsIndex = function () {
    return data;
  };
  return data;
}
function _object() {
  const data = _interopRequireDefault(require("./object"));
  _object = function () {
    return data;
  };
  return data;
}
function _objectList() {
  const data = require("./object-list");
  _objectList = function () {
    return data;
  };
  return data;
}
function _rawObject() {
  const data = _interopRequireDefault(require("./raw-object"));
  _rawObject = function () {
    return data;
  };
  return data;
}
function _ref() {
  const data = _interopRequireDefault(require("./ref"));
  _ref = function () {
    return data;
  };
  return data;
}
function _repositoryHooks() {
  const data = require("./repository-hooks");
  _repositoryHooks = function () {
    return data;
  };
  return data;
}
function _concurrency() {
  const data = require("../../utils/concurrency");
  _concurrency = function () {
    return data;
  };
  return data;
}
function _cacheFactory() {
  const data = require("../../cache/cache-factory");
  _cacheFactory = function () {
    return data;
  };
  return data;
}
function _inMemoryCache() {
  const data = require("../../cache/in-memory-cache");
  _inMemoryCache = function () {
    return data;
  };
  return data;
}
function _models() {
  const data = require("../models");
  _models = function () {
    return data;
  };
  return data;
}
function _getRequireWildcardCache(nodeInterop) { if (typeof WeakMap !== "function") return null; var cacheBabelInterop = new WeakMap(); var cacheNodeInterop = new WeakMap(); return (_getRequireWildcardCache = function (nodeInterop) { return nodeInterop ? cacheNodeInterop : cacheBabelInterop; })(nodeInterop); }
function _interopRequireWildcard(obj, nodeInterop) { if (!nodeInterop && obj && obj.__esModule) { return obj; } if (obj === null || typeof obj !== "object" && typeof obj !== "function") { return { default: obj }; } var cache = _getRequireWildcardCache(nodeInterop); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (key !== "default" && Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }
const OBJECTS_BACKUP_DIR = `${_constants().OBJECTS_DIR}.bak`;
class Repository {
  // @ts-ignore AUTO-ADDED-AFTER-MIGRATION-PLEASE-FIX!

  // @ts-ignore AUTO-ADDED-AFTER-MIGRATION-PLEASE-FIX!

  constructor(scopePath, scopeJson) {
    (0, _defineProperty2().default)(this, "objects", {});
    (0, _defineProperty2().default)(this, "objectsToRemove", []);
    (0, _defineProperty2().default)(this, "scopeJson", void 0);
    (0, _defineProperty2().default)(this, "onRead", void 0);
    (0, _defineProperty2().default)(this, "onPersist", void 0);
    (0, _defineProperty2().default)(this, "scopePath", void 0);
    (0, _defineProperty2().default)(this, "scopeIndex", void 0);
    (0, _defineProperty2().default)(this, "cache", void 0);
    (0, _defineProperty2().default)(this, "remoteLanes", void 0);
    (0, _defineProperty2().default)(this, "unmergedComponents", void 0);
    (0, _defineProperty2().default)(this, "persistMutex", new (_asyncMutex().Mutex)());
    this.scopePath = scopePath;
    this.scopeJson = scopeJson;
    this.onRead = (0, _repositoryHooks().onRead)(scopePath, scopeJson);
    this.onPersist = (0, _repositoryHooks().onPersist)(scopePath, scopeJson);
    this.cache = (0, _cacheFactory().createInMemoryCache)({
      maxSize: (0, _inMemoryCache().getMaxSizeForObjects)()
    });
  }
  static async load({
    scopePath,
    scopeJson
  }) {
    const repository = new Repository(scopePath, scopeJson);
    const scopeIndex = await repository.loadOptionallyCreateScopeIndex();
    repository.scopeIndex = scopeIndex;
    repository.remoteLanes = new (_remoteLanes().default)(scopePath);
    repository.unmergedComponents = await _unmergedComponents().default.load(scopePath);
    return repository;
  }
  static create({
    scopePath,
    scopeJson
  }) {
    const repository = new Repository(scopePath, scopeJson);
    const scopeIndex = _componentsIndex().default.create(scopePath);
    repository.scopeIndex = scopeIndex;
    return repository;
  }
  static reset(scopePath) {
    return _componentsIndex().default.reset(scopePath);
  }
  static getPathByScopePath(scopePath) {
    return path().join(scopePath, _constants().OBJECTS_DIR);
  }
  ensureDir() {
    return _fsExtra().default.ensureDir(this.getPath());
  }
  getPath() {
    return Repository.getPathByScopePath(this.scopePath);
  }
  getBackupPath(dirName) {
    const backupPath = path().join(this.scopePath, OBJECTS_BACKUP_DIR);
    return dirName ? path().join(backupPath, dirName) : backupPath;
  }
  getLicense() {
    // @ts-ignore AUTO-ADDED-AFTER-MIGRATION-PLEASE-FIX!
    return this.scopeJson.getPopulatedLicense();
  }
  async getScopeMetaObject() {
    const license = await this.getLicense();
    const object = _scopeMeta().default.fromObject({
      license,
      name: this.scopeJson.name
    });
    return {
      ref: object.hash(),
      buffer: await object.compress()
    };
  }
  objectPath(ref) {
    return path().join(this.getPath(), this.hashPath(ref));
  }
  async has(ref) {
    const objectPath = this.objectPath(ref);
    return _fsExtra().default.pathExists(objectPath);
  }
  async load(ref, throws = false, preferInMemoryObjects = false) {
    if (preferInMemoryObjects) {
      // during tag, the updated objects are in `this.objects`.
      // `this.cache` is less reliable, because if it reaches its max, then it loads from the filesystem, which may not
      // be there yet (in case of "version" object), or may be out-of-date (in case of "component" object).
      const inMemoryObjects = this.objects[ref.hash.toString()];
      if (inMemoryObjects) return inMemoryObjects;
    }
    const cached = this.getCache(ref);
    if (cached) {
      return cached;
    }
    let fileContentsRaw;
    const objectPath = this.objectPath(ref);
    try {
      fileContentsRaw = await _fsExtra().default.readFile(objectPath);
    } catch (err) {
      if (err.code !== 'ENOENT') {
        _logger().default.error(`Failed reading a ref file ${objectPath}. Error: ${err.message}`);
        throw err;
      }
      _logger().default.trace(`Failed finding a ref file ${objectPath}.`);
      if (throws) {
        // if we just `throw err` we loose the stack trace.
        // see https://stackoverflow.com/questions/68022123/no-stack-in-fs-promises-readfile-enoent-error
        const msg = `fatal: failed finding an object file ${objectPath} in the filesystem at ${err.path}`;
        throw Object.assign(err, {
          stack: new Error(msg).stack
        });
      }
      // @ts-ignore @todo: fix! it should return BitObject | null.
      return null;
    }
    const size = fileContentsRaw.byteLength;
    const fileContents = await this.onRead(fileContentsRaw);
    const parsedObject = await _object().default.parseObject(fileContents, objectPath);
    const maxSizeToCache = 100 * 1024; // 100KB
    if (size < maxSizeToCache) {
      // don't cache big files (mainly artifacts) to prevent out-of-memory
      this.setCache(parsedObject);
    }
    return parsedObject;
  }

  /**
   * this is restricted to provide objects according to the given types. Otherwise, big scopes (>1GB) could crush.
   * example usage: `this.list([ModelComponent, Symlink, Lane])`
   */
  async list(types) {
    const refs = await this.listRefs();
    const concurrency = (0, _concurrency().concurrentIOLimit)();
    const objects = [];
    await (0, _pMap().default)(refs, async ref => {
      const object = await this.load(ref);
      types.forEach(type => {
        if (object instanceof type || type.name === object.constructor.name // needed when Harmony calls this function
        ) objects.push(object);
      });
    }, {
      concurrency
    });
    return objects;
  }
  async listRefs(cwd = this.getPath()) {
    const matches = await (0, _utils().glob)(path().join('*', '*'), {
      cwd
    });
    const refs = matches.map(str => {
      const hash = str.replace(path().sep, '');
      if (!(0, _componentVersion().isHash)(hash)) {
        _logger().default.error(`fatal: the file "${str}" is not a valid bit object path`);
        return null;
      }
      return new (_ref().default)(hash);
    });
    return (0, _lodash().compact)(refs);
  }
  async listRawObjects() {
    const refs = await this.listRefs();
    const concurrency = (0, _concurrency().concurrentIOLimit)();
    return (0, _pMap().default)(refs, async ref => {
      try {
        const buffer = await this.loadRaw(ref);
        const bitRawObject = await _rawObject().default.fromDeflatedBuffer(buffer, ref.hash);
        return bitRawObject;
      } catch (err) {
        _logger().default.error(`Couldn't load the ref ${ref} this object is probably corrupted and should be delete`);
        return null;
      }
    }, {
      concurrency
    });
  }
  async listObjectsFromIndex(indexType, filter) {
    const hashes = filter ? this.scopeIndex.getHashesByQuery(indexType, filter) : this.scopeIndex.getHashes(indexType);
    return this._getBitObjectsByHashes(hashes);
  }
  getHashFromIndex(indexType, filter) {
    const hashes = this.scopeIndex.getHashesByQuery(indexType, filter);
    if (hashes.length > 2) throw new Error('getHashFromIndex expect to get zero or one result');
    return hashes.length ? hashes[0] : null;
  }
  async _getBitObjectsByHashes(hashes) {
    const bitObjects = await Promise.all(hashes.map(async hash => {
      const bitObject = await this.load(new (_ref().default)(hash));
      if (!bitObject) {
        const indexJsonPath = this.scopeIndex.getPath();
        if (this.scopeIndex.isFileOnBitHub()) {
          _logger().default.error(`repository._getBitObjectsByHashes, indexJson at "${indexJsonPath}" is outdated and needs to be deleted`);
          return null;
        }
        const indexItem = this.scopeIndex.find(hash);
        if (!indexItem) throw new Error(`_getBitObjectsByHashes failed finding ${hash}`);
        await this.scopeIndex.deleteFile();
        // @ts-ignore componentId must be set as it was retrieved from indexPath before
        throw new (_exceptions().OutdatedIndexJson)(indexItem.toIdentifierString(), indexJsonPath);
      }
      return bitObject;
    }));
    return (0, _lodash().compact)(bitObjects);
  }
  async loadOptionallyCreateScopeIndex() {
    try {
      const scopeIndex = await _componentsIndex().default.load(this.scopePath);
      return scopeIndex;
    } catch (err) {
      if (err.code === 'ENOENT') {
        const bitObjects = await this.list([_models().ModelComponent, _models().Symlink, _models().Lane]);
        const scopeIndex = _componentsIndex().default.create(this.scopePath);
        const added = scopeIndex.addMany(bitObjects);
        if (added) await scopeIndex.write();
        return scopeIndex;
      }
      throw err;
    }
  }
  async loadRaw(ref) {
    const raw = await _fsExtra().default.readFile(this.objectPath(ref));
    // Run hook to transform content pre reading
    const transformedContent = this.onRead(raw);
    return transformedContent;
  }
  async loadManyRaw(refs) {
    const concurrency = (0, _concurrency().concurrentIOLimit)();
    const uniqRefs = (0, _lodash().uniqBy)(refs, 'hash');
    return (0, _pMap().default)(uniqRefs, async ref => ({
      ref,
      buffer: await this.loadRaw(ref)
    }), {
      concurrency
    });
  }
  async loadManyRawIgnoreMissing(refs) {
    const concurrency = (0, _concurrency().concurrentIOLimit)();
    const results = await (0, _pMap().default)(refs, async ref => {
      try {
        const buffer = await this.loadRaw(ref);
        return {
          ref,
          buffer
        };
      } catch (err) {
        if (err.code === 'ENOENT') return null;
        throw err;
      }
    }, {
      concurrency
    });
    return (0, _lodash().compact)(results);
  }
  async loadRawObject(ref) {
    const buffer = await this.loadRaw(ref);
    const bitRawObject = await _rawObject().default.fromDeflatedBuffer(buffer, ref.hash);
    return bitRawObject;
  }

  /**
   * prefer using `this.load()` for an async version, which also writes to the cache
   */
  loadSync(ref, throws = true) {
    try {
      const objectFile = _fsExtra().default.readFileSync(this.objectPath(ref));
      // Run hook to transform content pre reading
      const transformedContent = this.onRead(objectFile);
      return _object().default.parseSync(transformedContent);
    } catch (err) {
      if (throws) {
        throw new (_exceptions().HashNotFound)(ref.toString());
      }
      // @ts-ignore AUTO-ADDED-AFTER-MIGRATION-PLEASE-FIX!
      return null;
    }
  }
  setCache(object) {
    this.cache.set(object.hash().toString(), object);
    return this;
  }
  getCache(ref) {
    return this.cache.get(ref.toString());
  }
  removeFromCache(ref) {
    this.cache.delete(ref.toString());
  }
  clearCache() {
    _logger().default.debug('repository.clearCache');
    this.cache.deleteAll();
  }
  backup(dirName) {
    const backupDir = this.getBackupPath(dirName);
    const objectsDir = this.getPath();
    _logger().default.debug(`making a backup of all objects from ${objectsDir} to ${backupDir}`);
    _fsExtra().default.emptyDirSync(backupDir);
    _fsExtra().default.copySync(objectsDir, backupDir);
  }
  add(object) {
    if (!object) return this;
    // leave the following commented log message, it is very useful for debugging but too verbose when not needed.
    // logger.debug(`repository: adding object ${object.hash().toString()} which consist of the following id: ${object.id()}`);
    this.objects[object.hash().toString()] = object;
    this.setCache(object);
    return this;
  }
  addMany(objects) {
    if (!objects || !objects.length) return this;
    objects.forEach(obj => this.add(obj));
    return this;
  }
  removeObject(ref) {
    this.objectsToRemove.push(ref);
  }
  removeManyObjects(refs) {
    if (!refs || !refs.length) return;
    refs.forEach(ref => this.removeObject(ref));
  }
  findMany(refs) {
    return Promise.all(refs.map(ref => this.load(ref)));
  }

  /**
   * important! use this method only for commands that are non running on an http server.
   *
   * it's better to remove/delete objects directly and not using the `objects` member.
   * it helps to avoid multiple processes running concurrently on an http server.
   *
   * persist objects changes (added and removed) into the filesystem
   * do not call this function multiple times in parallel, otherwise, it'll damage the index.json file.
   * call this function only once after you added and removed all applicable objects.
   */
  async persist(validate = true) {
    // do not let two requests enter this critical area, otherwise, refs/index.json/objects could
    // be corrupted
    _logger().default.debug(`Repository.persist, going to acquire a lock`);
    await this.persistMutex.runExclusive(async () => {
      _logger().default.debug(`Repository.persist, validate = ${validate.toString()}, a lock has been acquired`);
      await this.deleteObjectsFromFS(this.objectsToRemove);
      this.validateObjects(validate, Object.values(this.objects));
      await this.writeObjectsToTheFS(Object.values(this.objects));
      await this.writeRemoteLanes();
      await this.unmergedComponents.write();
    });
    _logger().default.debug(`Repository.persist, completed. the lock has been released`);
    this.clearObjects();
    if (Repository.onPostObjectsPersist) {
      Repository.onPostObjectsPersist().catch(err => {
        _logger().default.error('fatal: onPostObjectsPersist encountered an error (this error does not stop the process)', err);
      });
    }
  }
  async writeRemoteLanes() {
    await this.remoteLanes.write();
  }

  /**
   * this is especially critical for http server, where one process lives long and serves multiple
   * exports. without this, the objects get accumulated over time and being rewritten over and over
   * again.
   */
  clearObjects() {
    this.objects = {};
    this.objectsToRemove = [];
  }

  /**
   * normally, the validation step takes place just before the acutal writing of the file.
   * however, this can be an issue where a component has an invalid version. the component could
   * be saved before validating the version (see #1727). that's why we validate here before writing
   * anything to the filesystem.
   * the open question here is whether should we validate again before the actual writing or it
   * should be enough to validate here?
   * for now, it does validate again before saving, only to be 100% sure nothing happens in a few
   * lines of code until the actual writing. however, if the performance penalty is noticeable, we
   * can easily revert it by changing `bitObject.validateBeforePersist = false` line run regardless
   * the `validate` argument.
   */
  validateObjects(validate, objects) {
    objects.forEach(bitObject => {
      // @ts-ignore some BitObject classes have validate() method
      if (validate && bitObject.validate) {
        // @ts-ignore
        bitObject.validate();
      }
      if (!validate) {
        bitObject.validateBeforePersist = false;
      }
    });
  }
  async deleteObjectsFromFS(refs) {
    if (!refs.length) return;
    const uniqRefs = (0, _lodash().uniqBy)(refs, 'hash');
    _logger().default.debug(`Repository._deleteMany: deleting ${uniqRefs.length} objects`);
    const concurrency = (0, _concurrency().concurrentIOLimit)();
    await (0, _pMap().default)(uniqRefs, ref => this._deleteOne(ref), {
      concurrency
    });
    const removed = this.scopeIndex.removeMany(uniqRefs);
    if (removed) await this.scopeIndex.write();
  }
  async deleteRecordsFromUnmergedComponents(componentNames) {
    this.unmergedComponents.removeMultipleComponents(componentNames);
    await this.unmergedComponents.write();
  }

  /**
   * write all objects to the FS and index the components/lanes/symlink objects
   */
  async writeObjectsToTheFS(objects) {
    const count = objects.length;
    if (!count) return;
    _logger().default.trace(`Repository.writeObjectsToTheFS: started writing ${count} objects`);
    const concurrency = (0, _concurrency().concurrentIOLimit)();
    await (0, _pMap().default)(objects, obj => this._writeOne(obj), {
      concurrency
    });
    _logger().default.trace(`Repository.writeObjectsToTheFS: completed writing ${count} objects`);
    const added = this.scopeIndex.addMany(objects);
    if (added) await this.scopeIndex.write();
  }

  /**
   * do not call this method directly. always call this.removeObject() and once done with all objects,
   * call this.persist()
   */
  _deleteOne(ref) {
    this.removeFromCache(ref);
    const pathToDelete = this.objectPath(ref);
    _logger().default.trace(`repository._deleteOne: deleting ${pathToDelete}`);
    return (0, _fsRemoveFile().default)(pathToDelete, true);
  }

  /**
   * always prefer this.persist() or this.writeObjectsToTheFS()
   * this method doesn't write to scopeIndex. so using this method for ModelComponent or
   * Symlink makes the index outdated.
   */
  async _writeOne(object) {
    const contents = await object.compress();
    const options = {};
    if (this.scopeJson.groupName) options.gid = await (0, _utils().resolveGroupId)(this.scopeJson.groupName);
    const hash = object.hash();
    if (this.cache.has(hash.toString())) this.cache.set(hash.toString(), object); // update the cache
    const objectPath = this.objectPath(hash);
    _logger().default.trace(`repository._writeOne: ${objectPath}`);
    // Run hook to transform content pre persisting
    const transformedContent = this.onPersist(contents);
    // @ts-ignore AUTO-ADDED-AFTER-MIGRATION-PLEASE-FIX!
    return (0, _utils().writeFile)(objectPath, transformedContent, options);
  }
  async writeObjectsToPendingDir(objectList, pendingDir) {
    const options = {};
    if (this.scopeJson.groupName) options.gid = await (0, _utils().resolveGroupId)(this.scopeJson.groupName);
    await Promise.all(objectList.objects.map(async object => {
      const objPath = path().join(pendingDir, this.hashPath(object.ref));
      await (0, _utils().writeFile)(objPath, object.buffer, options);
    }));
  }
  async readObjectsFromPendingDir(pendingDir) {
    const refs = await this.listRefs(pendingDir);
    const objects = await Promise.all(refs.map(async ref => {
      const buffer = await _fsExtra().default.readFile(path().join(pendingDir, this.hashPath(ref)));
      return {
        ref,
        buffer
      };
    }));
    return new (_objectList().ObjectList)(objects);
  }
  hashPath(ref) {
    const hash = ref.toString();
    return path().join(hash.slice(0, 2), hash.slice(2));
  }
}
exports.default = Repository;
(0, _defineProperty2().default)(Repository, "onPostObjectsPersist", void 0);